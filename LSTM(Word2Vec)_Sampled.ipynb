{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM(Word2Vec)-Sampled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAmEZDAKqFvj",
        "outputId": "aed9a70b-d021-4771-d2d6-2c006d2875c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNt07qLcqIqv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pZQtLC-qVCF"
      },
      "source": [
        "# Reading the dataset\n",
        "\n",
        "project_path = '/content/drive/My Drive/Colab/'\n",
        "file_name ='TempOutput_1.xlsx'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67ED6lNRqcaS"
      },
      "source": [
        "unsampled_df=pd.read_excel(project_path+file_name)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyGpHgx4q6ez",
        "outputId": "54a8f85f-b1e1-4248-9e97-f37412178177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "unsampled_df.info()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7909 entries, 0 to 7908\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Unnamed: 0         7909 non-null   int64 \n",
            " 1   Short description  7909 non-null   object\n",
            " 2   Description        7906 non-null   object\n",
            " 3   Assignment group   7909 non-null   object\n",
            " 4   New Description    7876 non-null   object\n",
            " 5   Language           7909 non-null   object\n",
            " 6   Lemmatized clean   7909 non-null   object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 432.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFenneLtq7cc"
      },
      "source": [
        "unsampled_df.drop([\"Unnamed: 0\",\"Short description\", \"Description\", \"Language\"],axis=1,inplace=True)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tUdpw0Vq-wI",
        "outputId": "87601c86-fb48-434f-cf7a-c26feca67e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "unsampled_df.head(5)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>New Description</th>\n",
              "      <th>Lemmatized clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>login issue verified user details employee man...</td>\n",
              "      <td>['login', 'issue', 'verify', 'user', 'detail',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>outlook received from hmjdrvpb komuaywn team m...</td>\n",
              "      <td>['outlook', 'receive', 'hmjdrvpb', 'komuaywn',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>cannot log in to vpn received from eylqgodm yb...</td>\n",
              "      <td>['log', 'vpn', 'receive', 'eylqgodm', 'ybqkwia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to access hr tool page unable to access...</td>\n",
              "      <td>['unable', 'access', 'hr', 'tool', 'page', 'un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>['skype', 'error', 'skype', 'error']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Assignment group                                    New Description  \\\n",
              "0            GRP_0  login issue verified user details employee man...   \n",
              "1            GRP_0  outlook received from hmjdrvpb komuaywn team m...   \n",
              "2            GRP_0  cannot log in to vpn received from eylqgodm yb...   \n",
              "3            GRP_0  unable to access hr tool page unable to access...   \n",
              "4            GRP_0                            skype error skype error   \n",
              "\n",
              "                                    Lemmatized clean  \n",
              "0  ['login', 'issue', 'verify', 'user', 'detail',...  \n",
              "1  ['outlook', 'receive', 'hmjdrvpb', 'komuaywn',...  \n",
              "2  ['log', 'vpn', 'receive', 'eylqgodm', 'ybqkwia...  \n",
              "3  ['unable', 'access', 'hr', 'tool', 'page', 'un...  \n",
              "4               ['skype', 'error', 'skype', 'error']  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IweB6XSkPu_8",
        "outputId": "de12cbae-5266-4d96-eeba-78b0a08dfc90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "unsampled_df.isnull().sum()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Assignment group     0\n",
              "New Description     33\n",
              "Lemmatized clean     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQo4j7bgZC3W",
        "outputId": "1ea78d96-edd4-439e-d308-c6e89afb352e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "unsampled_df.isnull().sum()\n",
        "unsampled_df[unsampled_df.isnull().any(axis=1)]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>New Description</th>\n",
              "      <th>Lemmatized clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1625</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1631</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1860</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1861</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1906</th>\n",
              "      <td>GRP_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2951</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2966</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3138</th>\n",
              "      <td>GRP_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3529</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3683</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3857</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4231</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4232</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4233</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4824</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4960</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4968</th>\n",
              "      <td>GRP_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5384</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5522</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5698</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6092</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6093</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6806</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6811</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6814</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7062</th>\n",
              "      <td>GRP_30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7416</th>\n",
              "      <td>GRP_48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Assignment group New Description Lemmatized clean\n",
              "1038           GRP_48             NaN               []\n",
              "1127           GRP_30             NaN               []\n",
              "1386           GRP_30             NaN               []\n",
              "1621           GRP_48             NaN               []\n",
              "1622           GRP_48             NaN               []\n",
              "1625           GRP_48             NaN               []\n",
              "1631           GRP_48             NaN               []\n",
              "1860           GRP_30             NaN               []\n",
              "1861           GRP_30             NaN               []\n",
              "1906           GRP_31             NaN               []\n",
              "2951           GRP_30             NaN               []\n",
              "2966           GRP_30             NaN               []\n",
              "3138           GRP_31             NaN               []\n",
              "3529           GRP_48             NaN               []\n",
              "3683           GRP_30             NaN               []\n",
              "3857           GRP_30             NaN               []\n",
              "4231           GRP_48             NaN               []\n",
              "4232           GRP_48             NaN               []\n",
              "4233           GRP_48             NaN               []\n",
              "4822           GRP_48             NaN               []\n",
              "4824           GRP_30             NaN               []\n",
              "4960           GRP_30             NaN               []\n",
              "4968           GRP_31             NaN               []\n",
              "5384           GRP_48             NaN               []\n",
              "5522           GRP_30             NaN               []\n",
              "5698           GRP_30             NaN               []\n",
              "6092           GRP_48             NaN               []\n",
              "6093           GRP_48             NaN               []\n",
              "6806           GRP_30             NaN               []\n",
              "6811           GRP_48             NaN               []\n",
              "6814           GRP_48             NaN               []\n",
              "7062           GRP_30             NaN               []\n",
              "7416           GRP_48             NaN               []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojLQpmIKZHrh"
      },
      "source": [
        "unsampled_df = unsampled_df.dropna(axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVirHrAqYFuw"
      },
      "source": [
        "others_df = unsampled_df[unsampled_df['Assignment group'] != 'GRP_0']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyEE6Aj8YOFH",
        "outputId": "be3250d2-13f1-4b0b-b4d8-eb23ff92d3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxOthers = others_df['Assignment group'].value_counts().max()\n",
        "maxOthers"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euuBlqDGW1cw"
      },
      "source": [
        "# Upsample the minority classes and downsample the majority classes\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_to_process = unsampled_df[0:0]\n",
        "for grp in unsampled_df['Assignment group'].unique():\n",
        "    assign_grp_df = unsampled_df[unsampled_df['Assignment group'] == grp]\n",
        "    resampled = resample(assign_grp_df, replace=True, n_samples=maxOthers, random_state=123)\n",
        "    df_to_process = df_to_process.append(resampled)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D8unQkwtoGT",
        "outputId": "29828938-7a37-4348-c941-d0626986056d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn import preprocessing \n",
        "  \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "df_to_process['Assignment group ID']= label_encoder.fit_transform(df_to_process['Assignment group']) \n",
        "df_to_process['Assignment group ID'].unique()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1, 23, 34, 45, 56, 67, 72, 73,  2,  3,  4,  5,  6,  7,  8,  9,\n",
              "       10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28,\n",
              "       29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48,\n",
              "       49, 50, 51, 43, 52, 53, 54, 55, 57, 58, 26, 59, 60, 61, 62, 63, 64,\n",
              "       65, 66, 68, 69, 70, 71])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqlsXjHtuBBe"
      },
      "source": [
        "# Import the necessary libraries for modelling and plotting acuracy\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense, Activation\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# import the train test split package from scikit learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuCt1kzvwqgs",
        "outputId": "952846f7-ba12-4d5c-8c4c-089f270ed03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_to_process.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>New Description</th>\n",
              "      <th>Lemmatized clean</th>\n",
              "      <th>Assignment group ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2960</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>erp login trouble received from xosycftu olhpm...</td>\n",
              "      <td>['erp', 'login', 'trouble', 'receive', 'xosycf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2447</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>frequent account lock out frequent account loc...</td>\n",
              "      <td>['frequent', 'account', 'lock', 'frequent', 'a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>login issue login issue verified user details ...</td>\n",
              "      <td>['login', 'issue', 'login', 'issue', 'verify',...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7034</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>engineering tool is not working engineering to...</td>\n",
              "      <td>['engineering', 'tool', 'work', 'engineering',...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4911</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>not able to access sid received from miecoszw ...</td>\n",
              "      <td>['able', 'access', 'sid', 'receive', 'miecoszw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Assignment group                                    New Description  \\\n",
              "2960            GRP_0  erp login trouble received from xosycftu olhpm...   \n",
              "2447            GRP_0  frequent account lock out frequent account loc...   \n",
              "3996            GRP_0  login issue login issue verified user details ...   \n",
              "7034            GRP_0  engineering tool is not working engineering to...   \n",
              "4911            GRP_0  not able to access sid received from miecoszw ...   \n",
              "\n",
              "                                       Lemmatized clean  Assignment group ID  \n",
              "2960  ['erp', 'login', 'trouble', 'receive', 'xosycf...                    0  \n",
              "2447  ['frequent', 'account', 'lock', 'frequent', 'a...                    0  \n",
              "3996  ['login', 'issue', 'login', 'issue', 'verify',...                    0  \n",
              "7034  ['engineering', 'tool', 'work', 'engineering',...                    0  \n",
              "4911  ['able', 'access', 'sid', 'receive', 'miecoszw...                    0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPKUVXNZ-4tX"
      },
      "source": [
        "def wordTokenizer(dataframe):\n",
        "    tokenizer = Tokenizer(num_words=numWords,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=' ', char_level=False)\n",
        "    tokenizer.fit_on_texts(dataframe)\n",
        "    dataframe = tokenizer.texts_to_sequences(dataframe)\n",
        "    return tokenizer,dataframe"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ondqXRiHuD20",
        "outputId": "aa86c1ce-8993-42ec-945d-ce2f0301c380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Word2Vec the dataframe and store the embedding result\n",
        "sentences = [line.split(' ') for line in df_to_process['New Description']] \n",
        "word2vec = Word2Vec(sentences=sentences,min_count=1)\n",
        "word2vec.wv.save_word2vec_format(project_path+'word2vec.txt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XFRJImZuEob",
        "outputId": "a16e048d-cead-4c37-f6e3-db918d5e9f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the embedding into memory\n",
        "embedding_indices = dict()\n",
        "f = open(project_path+'word2vec.txt')\n",
        "\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coeff = np.array(values[1:], dtype='float32')\n",
        "  embedding_indices[word] = coeff\n",
        "f.close()\n",
        "\n",
        "len(embedding_indices)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-AqksO56pVP"
      },
      "source": [
        "results = pd.DataFrame()\n",
        "predictedResults = pd.DataFrame()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eum7UwuF6r0H",
        "outputId": "38af7354-92f2-4354-9540-e0bd35dbb2b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_to_process.head(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>New Description</th>\n",
              "      <th>Lemmatized clean</th>\n",
              "      <th>Assignment group ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2960</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>erp login trouble received from xosycftu olhpm...</td>\n",
              "      <td>['erp', 'login', 'trouble', 'receive', 'xosycf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2447</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>frequent account lock out frequent account loc...</td>\n",
              "      <td>['frequent', 'account', 'lock', 'frequent', 'a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>login issue login issue verified user details ...</td>\n",
              "      <td>['login', 'issue', 'login', 'issue', 'verify',...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7034</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>engineering tool is not working engineering to...</td>\n",
              "      <td>['engineering', 'tool', 'work', 'engineering',...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4911</th>\n",
              "      <td>GRP_0</td>\n",
              "      <td>not able to access sid received from miecoszw ...</td>\n",
              "      <td>['able', 'access', 'sid', 'receive', 'miecoszw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Assignment group                                    New Description  \\\n",
              "2960            GRP_0  erp login trouble received from xosycftu olhpm...   \n",
              "2447            GRP_0  frequent account lock out frequent account loc...   \n",
              "3996            GRP_0  login issue login issue verified user details ...   \n",
              "7034            GRP_0  engineering tool is not working engineering to...   \n",
              "4911            GRP_0  not able to access sid received from miecoszw ...   \n",
              "\n",
              "                                       Lemmatized clean  Assignment group ID  \n",
              "2960  ['erp', 'login', 'trouble', 'receive', 'xosycf...                    0  \n",
              "2447  ['frequent', 'account', 'lock', 'frequent', 'a...                    0  \n",
              "3996  ['login', 'issue', 'login', 'issue', 'verify',...                    0  \n",
              "7034  ['engineering', 'tool', 'work', 'engineering',...                    0  \n",
              "4911  ['able', 'access', 'sid', 'receive', 'miecoszw...                    0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7IjWCec_JB6"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 300\n",
        "tokenizer = Tokenizer(split=' ')\n",
        "tokenizer.fit_on_texts(df_to_process[\"New Description\"].values)\n",
        "X_seq = tokenizer.texts_to_sequences(df_to_process[\"New Description\"].values)\n",
        "X_padded = pad_sequences(X_seq, maxlen=max_len)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_t1UmfoKTHi",
        "outputId": "6b8bb446-18c7-4387-97f8-dfd0e1d635ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numWords = len(tokenizer.word_index) + 1\n",
        "epochs = 20\n",
        "batch_size=100\n",
        "numWords"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Ih_FN2_xlD"
      },
      "source": [
        "# Try the BiLSTM model on the raw or unsampled data and predict the accuracy.\n",
        "\n",
        "# Tokenize\n",
        "tokenizer, X = wordTokenizer(df_to_process['New Description'])\n",
        "y = np.asarray(df_to_process['Assignment group ID'])\n",
        "X = pad_sequences(X,maxlen=max_len)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXx3vrlQuVr9",
        "outputId": "932c65e4-8bba-4131-9e42-d7d45725ac27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Create embedding matrix\n",
        "\n",
        "embedding_matrix = np.zeros((numWords+1,100))\n",
        "\n",
        "for i,word in tokenizer.index_word.items():\n",
        "  if i<numWords+1:\n",
        "    embedding_vector = embedding_indices.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 1.15348303e+00, -1.09320033e+00, -3.00817060e+00, ...,\n",
              "         1.23354208e+00, -1.54826438e+00, -1.24885929e+00],\n",
              "       [ 3.31065506e-01, -1.81466675e+00, -8.92821550e-01, ...,\n",
              "         7.09591568e-01, -1.43603134e+00, -1.08622420e+00],\n",
              "       ...,\n",
              "       [-7.80330366e-03, -9.29059577e-04,  2.08052583e-02, ...,\n",
              "         1.79445501e-02, -2.19938830e-02,  2.06781086e-02],\n",
              "       [-3.98038886e-03, -4.15516784e-03,  1.76522266e-02, ...,\n",
              "         1.95057504e-02, -2.43130829e-02,  1.50261121e-02],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXqT-Q8cIO82"
      },
      "source": [
        "LSTM_w2v_unsampled_weights_df = pd.DataFrame(embedding_matrix)\n",
        "LSTM_w2v_unsampled_weights_df.to_excel(project_path+'LSTM_w2v_unsampled_weights.xlsx', index = True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YheKYV7quZet"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99WPyShLBwHT",
        "outputId": "a1cc857b-34f2-4ae1-9d48-ea6387b781f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "X_train,X_test,y_train,y_test"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   0,    0,    0, ...,   44,    6, 1337],\n",
              "        [   0,    0,    0, ...,  560,   27,  591],\n",
              "        [   0,    0,    0, ...,   14,   43,   20],\n",
              "        ...,\n",
              "        [   0,    0,    0, ...,   14,   43,   20],\n",
              "        [   0,    0,    0, ...,    0,    0,    1],\n",
              "        [   0,    0,    0, ...,    3,    2,  140]], dtype=int32),\n",
              " array([[   0,    0,    0, ...,  720,  204,    9],\n",
              "        [   0,    0,    0, ...,  259,  125,  126],\n",
              "        [   0,    0,    0, ...,  166,  233,    1],\n",
              "        ...,\n",
              "        [   0,    0,    0, ..., 3195, 2294, 1024],\n",
              "        [   0,    0,    0, ...,  318,    1,   68],\n",
              "        [   0,    0,    0, ...,   38,  122,  248]], dtype=int32),\n",
              " array([60, 61, 45, ..., 53, 24, 66]),\n",
              " array([50, 64,  1, ..., 17, 68, 58]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZrTkshBaNk",
        "outputId": "973f0edf-e0b8-468f-dafc-a1d2aecf7d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "(pd.Series(y_train)).unique()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([60, 61, 45, 34,  8, 55, 65, 36, 54, 70, 56,  2, 31, 14, 41, 66, 24,\n",
              "       64, 67, 16, 53,  0, 37, 63, 59,  4, 50, 29, 58, 15, 51, 39, 22, 71,\n",
              "       12, 28, 20, 35, 33, 18, 25, 57, 73, 52,  1, 47, 42,  9, 44, 30, 69,\n",
              "       13, 43, 23, 26, 72,  7, 27, 10,  5, 17, 68, 48, 32, 46, 11,  3, 40,\n",
              "       62, 49, 19, 21,  6, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6leC6fDzudb3",
        "outputId": "9885e764-7484-40ce-ef33-fbeffb563b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "input_layer = Input(shape=(max_len,),dtype=tf.int64)\n",
        "embed = Embedding(numWords+1,output_dim=100,input_length=max_len,weights=[embedding_matrix], trainable=True)(input_layer)  #weights=[embedding_matrix]\n",
        "lstm=Bidirectional(LSTM(128))(embed)\n",
        "drop=Dropout(0.3)(lstm)\n",
        "dense =Dense(100,activation='relu')(drop)\n",
        "out=Dense((len((pd.Series(y_train)).unique())+1),activation='softmax')(dense)   \n",
        "\n",
        "model = Model(input_layer,out)\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "plot_model(model,to_file=\"LSTM_Model.jpg\")\n",
        "\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}-{val_accuracy:03f}.h5', verbose=1, monitor='val_accuracy',save_best_only=True, mode='auto') \n",
        "reduceLoss = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=2, min_lr=0.0001)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 300)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 300, 100)          1234400   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               234496    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               25700     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 75)                7575      \n",
            "=================================================================\n",
            "Total params: 1,502,171\n",
            "Trainable params: 1,502,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxrS-3fn7Kp1",
        "outputId": "4ef6fd5d-3bae-4985-b8d0-3c4d9771673d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_history = model.fit(X_train,y_train,batch_size=batch_size, epochs=epochs, callbacks=[checkpoint,reduceLoss], validation_data=(X_test,y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 1.8583 - accuracy: 0.5522\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79552, saving model to model-001-0.795516.h5\n",
            "335/335 [==============================] - 54s 160ms/step - loss: 1.8583 - accuracy: 0.5522 - val_loss: 0.7426 - val_accuracy: 0.7955\n",
            "Epoch 2/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.8274\n",
            "Epoch 00002: val_accuracy improved from 0.79552 to 0.88344, saving model to model-002-0.883442.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.6169 - accuracy: 0.8274 - val_loss: 0.4030 - val_accuracy: 0.8834\n",
            "Epoch 3/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8857\n",
            "Epoch 00003: val_accuracy improved from 0.88344 to 0.91564, saving model to model-003-0.915637.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.3873 - accuracy: 0.8857 - val_loss: 0.2944 - val_accuracy: 0.9156\n",
            "Epoch 4/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9182\n",
            "Epoch 00004: val_accuracy improved from 0.91564 to 0.93051, saving model to model-004-0.930512.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.2719 - accuracy: 0.9182 - val_loss: 0.2335 - val_accuracy: 0.9305\n",
            "Epoch 5/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9302\n",
            "Epoch 00005: val_accuracy improved from 0.93051 to 0.93414, saving model to model-005-0.934143.h5\n",
            "335/335 [==============================] - 52s 157ms/step - loss: 0.2337 - accuracy: 0.9302 - val_loss: 0.2211 - val_accuracy: 0.9341\n",
            "Epoch 6/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.9406\n",
            "Epoch 00006: val_accuracy improved from 0.93414 to 0.93617, saving model to model-006-0.936169.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.1955 - accuracy: 0.9406 - val_loss: 0.2103 - val_accuracy: 0.9362\n",
            "Epoch 7/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9422\n",
            "Epoch 00007: val_accuracy improved from 0.93617 to 0.94657, saving model to model-007-0.946575.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.1847 - accuracy: 0.9422 - val_loss: 0.1843 - val_accuracy: 0.9466\n",
            "Epoch 8/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9487\n",
            "Epoch 00008: val_accuracy improved from 0.94657 to 0.94741, saving model to model-008-0.947413.h5\n",
            "335/335 [==============================] - 52s 156ms/step - loss: 0.1651 - accuracy: 0.9487 - val_loss: 0.1759 - val_accuracy: 0.9474\n",
            "Epoch 9/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9519\n",
            "Epoch 00009: val_accuracy did not improve from 0.94741\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.1482 - accuracy: 0.9519 - val_loss: 0.1722 - val_accuracy: 0.9473\n",
            "Epoch 10/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9545\n",
            "Epoch 00010: val_accuracy improved from 0.94741 to 0.94790, saving model to model-010-0.947901.h5\n",
            "335/335 [==============================] - 52s 156ms/step - loss: 0.1387 - accuracy: 0.9545 - val_loss: 0.1703 - val_accuracy: 0.9479\n",
            "Epoch 11/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9509\n",
            "Epoch 00011: val_accuracy improved from 0.94790 to 0.94944, saving model to model-011-0.949438.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.1522 - accuracy: 0.9509 - val_loss: 0.1740 - val_accuracy: 0.9494\n",
            "Epoch 12/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9560\n",
            "Epoch 00012: val_accuracy did not improve from 0.94944\n",
            "335/335 [==============================] - 52s 156ms/step - loss: 0.1345 - accuracy: 0.9560 - val_loss: 0.1795 - val_accuracy: 0.9480\n",
            "Epoch 13/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9592\n",
            "Epoch 00013: val_accuracy improved from 0.94944 to 0.95167, saving model to model-013-0.951673.h5\n",
            "335/335 [==============================] - 52s 157ms/step - loss: 0.1193 - accuracy: 0.9592 - val_loss: 0.1599 - val_accuracy: 0.9517\n",
            "Epoch 14/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9620\n",
            "Epoch 00014: val_accuracy did not improve from 0.95167\n",
            "335/335 [==============================] - 52s 157ms/step - loss: 0.1132 - accuracy: 0.9620 - val_loss: 0.1622 - val_accuracy: 0.9507\n",
            "Epoch 15/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9603\n",
            "Epoch 00015: val_accuracy did not improve from 0.95167\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.1127 - accuracy: 0.9603 - val_loss: 0.1626 - val_accuracy: 0.9515\n",
            "Epoch 16/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9613\n",
            "Epoch 00016: val_accuracy did not improve from 0.95167\n",
            "335/335 [==============================] - 52s 157ms/step - loss: 0.1114 - accuracy: 0.9613 - val_loss: 0.1618 - val_accuracy: 0.9511\n",
            "Epoch 17/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9611\n",
            "Epoch 00017: val_accuracy did not improve from 0.95167\n",
            "335/335 [==============================] - 52s 156ms/step - loss: 0.1097 - accuracy: 0.9611 - val_loss: 0.1620 - val_accuracy: 0.9512\n",
            "Epoch 18/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9614\n",
            "Epoch 00018: val_accuracy improved from 0.95167 to 0.95181, saving model to model-018-0.951812.h5\n",
            "335/335 [==============================] - 53s 157ms/step - loss: 0.1090 - accuracy: 0.9614 - val_loss: 0.1622 - val_accuracy: 0.9518\n",
            "Epoch 19/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9615\n",
            "Epoch 00019: val_accuracy did not improve from 0.95181\n",
            "335/335 [==============================] - 52s 157ms/step - loss: 0.1083 - accuracy: 0.9615 - val_loss: 0.1614 - val_accuracy: 0.9516\n",
            "Epoch 20/20\n",
            "335/335 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.9622\n",
            "Epoch 00020: val_accuracy did not improve from 0.95181\n",
            "335/335 [==============================] - 52s 157ms/step - loss: 0.1085 - accuracy: 0.9622 - val_loss: 0.1621 - val_accuracy: 0.9517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roIPIyWkRvuM",
        "outputId": "45f2ed8d-4501-490a-dfb3-82766be86e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.5626590251922607,\n",
              "  0.8232318758964539,\n",
              "  0.8896471261978149,\n",
              "  0.9196671843528748,\n",
              "  0.9308611154556274,\n",
              "  0.9337044954299927,\n",
              "  0.9429828524589539,\n",
              "  0.9475921392440796,\n",
              "  0.9497470855712891,\n",
              "  0.956212043762207,\n",
              "  0.958157479763031,\n",
              "  0.9580976366996765,\n",
              "  0.9591152667999268,\n",
              "  0.9588159322738647,\n",
              "  0.9597437977790833,\n",
              "  0.958995521068573,\n",
              "  0.9601628184318542,\n",
              "  0.9612103700637817,\n",
              "  0.9603723287582397,\n",
              "  0.9587560892105103],\n",
              " 'loss': [1.838984489440918,\n",
              "  0.6232320070266724,\n",
              "  0.37952929735183716,\n",
              "  0.27495241165161133,\n",
              "  0.22788368165493011,\n",
              "  0.21699371933937073,\n",
              "  0.18229874968528748,\n",
              "  0.1670667976140976,\n",
              "  0.15365836024284363,\n",
              "  0.13392972946166992,\n",
              "  0.12528900802135468,\n",
              "  0.12182215601205826,\n",
              "  0.12070159614086151,\n",
              "  0.11963889002799988,\n",
              "  0.11750727891921997,\n",
              "  0.11600662767887115,\n",
              "  0.11564932763576508,\n",
              "  0.11442184448242188,\n",
              "  0.1148597002029419,\n",
              "  0.11593712121248245],\n",
              " 'lr': [0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.001,\n",
              "  0.00020000001,\n",
              "  0.00020000001,\n",
              "  0.00020000001,\n",
              "  0.00020000001,\n",
              "  0.00020000001,\n",
              "  1e-04,\n",
              "  1e-04,\n",
              "  1e-04,\n",
              "  1e-04,\n",
              "  1e-04,\n",
              "  1e-04],\n",
              " 'val_accuracy': [0.7902088165283203,\n",
              "  0.8809274435043335,\n",
              "  0.9159159064292908,\n",
              "  0.9240170121192932,\n",
              "  0.9406383037567139,\n",
              "  0.9370067715644836,\n",
              "  0.9419652223587036,\n",
              "  0.9462252855300903,\n",
              "  0.9483203887939453,\n",
              "  0.9514631032943726,\n",
              "  0.9507647156715393,\n",
              "  0.95174241065979,\n",
              "  0.9499965310096741,\n",
              "  0.9525805115699768,\n",
              "  0.9530693292617798,\n",
              "  0.9513932466506958,\n",
              "  0.9525106549263,\n",
              "  0.951323390007019,\n",
              "  0.9503456950187683,\n",
              "  0.9536978602409363],\n",
              " 'val_loss': [0.7386316061019897,\n",
              "  0.4061358571052551,\n",
              "  0.2937731444835663,\n",
              "  0.24572935700416565,\n",
              "  0.20406825840473175,\n",
              "  0.21487219631671906,\n",
              "  0.1821083277463913,\n",
              "  0.18660929799079895,\n",
              "  0.18414248526096344,\n",
              "  0.16689710319042206,\n",
              "  0.1659984141588211,\n",
              "  0.16560320556163788,\n",
              "  0.16685837507247925,\n",
              "  0.1666908711194992,\n",
              "  0.16672685742378235,\n",
              "  0.16393648087978363,\n",
              "  0.16659067571163177,\n",
              "  0.16704660654067993,\n",
              "  0.16870711743831635,\n",
              "  0.16767644882202148]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF3cnBr9VF_o",
        "outputId": "b7988035-9c43-4979-f2fa-cf431066aa74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plotting losses\n",
        "loss_values = model_history.history['loss']\n",
        "val_loss_values = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss_values, 'b', label=\"Validation Loss\")\n",
        "\n",
        "plt.title('LSTM on sampled data - Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7-u41URKxq",
        "outputId": "5f619eb7-cf15-4201-a6b1-b7c99d9868e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Training and Validation Accuracy\n",
        "\n",
        "acc_values = model_history.history['accuracy']\n",
        "val_acc_values = model_history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, acc_values, 'ro', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc_values, 'r', label=\"Validation Accuracy\")\n",
        "\n",
        "plt.title('LSTM on sampled data - Training and Validation Accuraccy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU1dn38e/NAA6bIIsbIGhEVILDJu6KSxTBgKgoCCqSoPBqDCTGGPVRHxOy6WPUhCy4IYqAxKAYcWNxiWhkCaAgRpBBQEBE2Ry2Yc77x6keaprump6lp3uY3+e6+ura6+7q6rqrzqk+Zc45REREkqmV6QBERCS7KVGIiEgkJQoREYmkRCEiIpGUKEREJJIShYiIRFKiqEHMrIeZramKec3sTTP7YXnWla3MbJCZvV7Z02aSmd1rZs+kYblDzOxfof7tZnZMKtOWY12vmNl15Z1fSpd1icLM8s3sgiTj7jCzlcFOt8bMJgfDlwTDtpvZXjPbGeq/I9gRnZn9IW55fYPh46rgo0kSUd95JSz7r6F9YbeZ7Qn1v1KWZTnnJjjnLqzsabORmbU0s0Iz+06CcVPN7IGyLM8519A591klxLVfYnPOXeyce6qiyy5lnc7MTknXOrJd1iWKZIIzhmuAC5xzDYFuwEwA51yHYEdsCLwD3Bzrd879OljECuBKM6sdWux1wH+r7lNIVXPODQ/tG78GJof2jYtj08XtFzWec24t/vd1TXi4mTUFegFpOzBnEzMz4Frg6+C9KtedNftktUkUwMnAa865FQDOufXOubFlmH898CFwERTv8KcD06JmMrNhZrbczL42s2lmdmRonDOz4Wb2qZltNrMxwY6VaDndzWyemW01sw1m9mBo3BQzW29mW8zsbTPrEBo3zsz+HFxebzezd83scDN7yMy+MbNlZtY5NH2+mf3CzJYG4580s9wkMR1pZs+b2cbgSu2W0Lh6wbq/MbOl+O0ftZ2+F8Syxcz+BFho3HfMbJaZbTKzr8xsgpk1CcY9DRwFvBR8vttK2yaVJdhWPzezxcC3ZlbbzG43sxVmti3Yhv1C08cXpyT9/ss4bY6Z/V+wbVaa2c3B9AkPFKnEaGYPBN/dSjMLJ8SjzeytYN43gOYRm+gp4hIFMABY6pz7MCqOBDE7Mzs26G4W/Ja2mtkHwHfipn3YzFYH4+eb2VnB8J7AHcBVwb6yKBheXMxpZrXM7C4zW2VmX5rZeDNrHIxrG8RxnZl9HmzvOyM+P8BZwBHALcAAM6sbirNe8L2tCvbTf5lZvWDcmWY2J/iuV5vZkPhYg/5E+8lNZvYp8GnU9gjG5ZgvNYl9D/PNrHUwroOZvWH+2LUhmO5wMysws2ahZXQxfwyok3QrOOey6gXk468a4ocPxmf1n+GvJnKSzP8m8MO4YUOAfwFX488oAf4f8DfgV8C4JMs6D/gK6AIcBPwReDs03gH/BJrgD3YbgZ5JlvUecE3Q3RA4NTRuKNAoWMdDwMLQuHFBDF2BXGAWsBJ/dpMTxD87bvt9BLQGmgLvAr8KxvUA1gTdtYD5wN1AXeAY4DPgomD8b/FXZ02DZX0UmzfBZ2sObAOuAOoAo4DC2PcAHAt8L/h8LYC3gYeivvOobVKBfete4Jm49S4MPl+9YFh/4Mhg+1wFfAscEd6PUvn+yzjtcGAp0Ao4BJgRTF87yecoLcY9wLBg/xgBfAFYaD98MNiuZwff2zNJ1lMP2AKcGbcfjyzntjo26J4EPAc0AL4LrI2bdjDQDKgN/BR/kpeb6DuM/80H+81y/P7cEPgH8HQwrm0Qx6PBZ8sDdgEnROwzjwex1gE2AZeHxo0J1t0y2NanB9u1TbBdBwbzNQM6JTo+JdlOb+B/d/VS2B4/w58At8efnOUF0zYC1gXT5wb9pwTzTAdGhNb5B+CPkb+div74KvtFkkQRjBuE/xF9G3xpP08wTYkvIvxlBDvHBqAx8D5wBtGJ4nHg96H+hvgfYdvQlxr+ET0H3J5kWW8D/ws0L+XzNwmW2zjoHwc8Ghr/I+DjUH9HYHPc9hse6u8FrAi6e7AvUZwCfB637l8ATwbdnxFKesANJE8U1wLvh/oNWBP/PYTGXwr8J5XvPNE2qcC+dS/7J4qhpcyzEOgb3o9C45J+/2WcdhZwY2jcBUQkihRiXB4aVz9Y1uH4BFUINAiNf5YkiSIY/xgwNuhuB+wGDi3ntjoWf0DdAxwfGvfr8LQJlvsNkJfoOwyGvcm+RDET+H+hce2D9dVmX6JoFRr/ATAgyXrrA1uBS4P+vwEvBt21gB2xuBL8jqYmWWZxrBHb6bxSvu/w9vgkts3jphlI6DcWN+4q4N2gOwefeLpHrbM6FT3hfAXhBfgDx3Dgl2Z2URnm3wG8DNwFNHPOvVvKLEcCq0Lzb8cnqJahadaHugvwySSRHwDHAcvMbK6ZXQLFl46/DS4dt+IPXlCySGBDqHtHgv74da4Oda8KPke8NsCRwaXxZjPbjL+sPywYf2SC5SRTYlrn98DifjM7zMwmmdna4DM+Q0SRR4rbJDbtWbavcnpJRIzJhD8jZnatmS0MbZPvRsVK6t9/1LTx27pETPFSiLF4Pc65gqCzYbCeb5xz34amjfpewRc/9TdffHkNvvj3yxTjSKQF/qCddN8ys1vN7OOgOGcz/sSutOXGlPjNBt212bdfQ+rfWT98Yp0e9E8ALjazFkE8ufi6z3itkwxPVfw+GbU9kq0rKoYXgRPN7Gj8lf4W59wHUQFVq0QR45zb45ybAizG75xlMR5/OZbKLYFf4A+oAJhZA/xl3doyrhPn3KfOuYHAocDvgL8Hy7sa6Is/i2yMP+uBUBl/ObQOdR+F/xzxVgMrnXNNQq9Gzrlewfh1CZaTTIlpzczi5v01/kypo3PuYPyldPjzubjlpbxNnHPvuH2V0+Wpxyhet5m1wRdL3Iw/kWiCL3KryHeRinX4YqeY1skmrGCM64BDgv0uJup7BX8l/jX++xhMUIldgTg24g++CfetoPz9NuBK4JBguVtCy43fV+KV+M2y7ypqQ+LJI12HTyKfm9l6YAq+KOlqfHHwTuLqVwKrkwwHXxpSP9R/eIJpwvtkadsj2bpW44vf9l+4czvxV7SD8cn/6SSxFsvWRFHHzHJDr9pBpU9vM2sUVFhdDHQA/l3GZb+Fz6J/TGHaicD1ZtbJzA7CH/D+7ZzLL+M6MbPBZtbCOVcEbA4GF+HLDnfhr1TqB+uoqJvMrJX5Cvs7gckJpvkA2Ga+MrdecBb/XTOLVVo/B/zCzA4xs1b4Iq9kXgY6mNll5itgb6HkD6ARsB3YYmYt8eWqYRsouVOnY5ukogH+R7oRwMyup+wnIuXxHPBj87ekNgF+HjFtuWN0zq0C5gH/a2Z1zexM4PulzOPwJ1e/w1/Jv1SROJxze/H1BveaWX0zOxF/QI5phD+wbwRqm9ndwMGh8RuAtmaW7Ng1ERhlvtI+fKdbYWmxhQX76fnAJUCn4JWH3w7XBr/jJ4AHzd8UkmNmpwXHiQnABWZ2ZXDsamZmnYJFLwQuCz77sfiShiilbY/H8CUr7cw7Kaio/idwhJmNNLODguNm+Pbe8fhirz5U40QxHV+kEnvdiy8rvAP4HH+g/T2+QqZMf9Rx3kzn3NcpTDsD+B/gefzZ2Hfwd32UR09giZltBx7Gl4vuwH9hq/BXKUvxdScV9SzwOr6eYQW+HqaE4Acb+xGsxJ8hPYY/gwdfn7IqGPc6ETuTc+4rfMXmb/EH93b4SvSY/8XfELAFn1T+EbeI3wB3BUUYt5KebVIq59xS4P/wFbYb8PU/pRVPVoZH8dt4MfAf/P5fCOxNQ4xX4+unvgbuwW/r0ozHn5lPds7tqoQ4bsafqa/H18E9GRr3GvAq/rb1Vfiz9nBRzJTgfZOZLUiw7Cfw++rb+H13J9EnOclcg7+B4nXn77Bc75xbDzwCnGRm3wVuxVckz8Vvz98BtZxzn+PrBn8aDF+ITzLgK45347fZU/ikEqW07fEg/kTjdfwx8nF8Jfg2/Anx9/Hb+VPg3NhMQbF7EbAgOIGIFLsTQg4QZpaPryybkelYpHyCq+W/OufalDqxSDmZ2SzgWefcY6VNm61XFCI1RlD01ysopmiJP9Ofmum45MAVFDF3IXGx9H6UKEQyz/DFc9/gi54+xv+/RaTSmdlT+L8ZjAyKqEqfR0VPIiISRVcUIiISKWsanUpV8+bNXdu2bTMdhohItTJ//vyvnHMtyjNvtUsUbdu2Zd68eZkOQ0SkWjGzUm+DTUZFTyIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChEpHQTJkDbtlCrln+fUFpbdlKpMrz9lShEJNqECXDDDbBqFTjn32+4oWwHq4oe6Gry/JWx/Ssq6vF32fjq2rWrE5EyeuYZ59q0cc7Mvz/zTOrztmnjnD9ElXy1aZP6uuvXLzlv/fqpx1DT56/o9g8A81w5j7sZP/CX9aVEITVSRQ70FT1QmSU+UJmlNn9FD3Q1ff6Kbv9ARRKFip5ESpPp8vmKFj3ceScUFJQcVlDgh6fiqCRPS002PN7nn5dtuOYvqaLbvxIoUciBr7qXD1f0QF/RA9Xo0VC/fslh9ev74amo6IGups9f0e1fGcp7KZKpl4qepEyyoXy4IsVGzmW+6KeinyHTZfzVff7YMiqyD7mKFT1Vu+dRdOvWzalRwBpmwgR/9vz55/4sbPRoGDQotXnbtvVXAfHatIH8/NLnr1XL/7TjmUFRUenzx65IwlcE9evD2LHp/wx798L69fDYY/DrX8Pu3fvG1a0LI0bAhRdCbi4cdFD0e506/jOD/9y7d5f+2rNnX/cbb8DTT8NXX0GLFjB4MJx/PuTk+G2ck7Pvlaj/1VfhkUdg3To44gj48Y+hd+99303Uu3MwfTqMGeO3x2GHwQ9+AOec42OMvQoLS/aHX/Pm+c+wZQs0bgzf+x507uy3Sa1a+96Tdc+dC9OmwddfQ9Om8P3vw8knJ0rffvsmTu1w0UV+veVgZvOdc93KNa8ShWS1ih5oK3qgL8tB2jnYuRO2b/evb7/1B5T16/ef/7DD4JVXoEGDfa/69f0BPF6ibVCvnj/4d+sGa9bs/1q71h9U9+4t/TOmqm5dv7zKXKaUzV/+AsOHl2vWiiSKatfMuFRzRUX+DG3XLn+mWdr7qFGJy+d//GN/Bgj7znQTvTdr5s9i4x1yCPz5z/vOIgsLE3e3b+8PurF1gU8+ubnQpcu+hBBLDqkkH4ANG/z88WrXLpk4Yt3HHAMrVsCOHX79O3b4bRPWoAG0bg2tWsEFF/j38Ovww318u3b5hFbW9927fXx165Z81amz/7BE42oHh5tYsikqStwdNS7Rdxz1/cdPU7u2jynZK2p8LP7YGX9RUcnuRMPiu2OxJHvFrkKSverUSW3/qmS6opD0WrvWFxtNnuwPNtVBTo4/KMReRUU+Oe3d6/tbt/ZXFA0b+leDBvu6w68GDeDmm+HLL/dfx6GHwl//6pPMt9/65ce6k/Xv2uWvROITQOx18MH7DogicXRFIelVljoC52DZMnjhBf/64IP9p6lTB/r3h9NO82eaBx2U/L1fv8RFN0ceCf/6V+ll0wAvvggPPQRffOHnu+02uOKKfWeJsbPI2rX3lYlXlt27ExedPfig/2wi1UF5a8Ez9dJdT1UslTs29u51bs4c5267zbnjjts3XffuzjVpUrE7birjjpFMq4Q7VkQqCt31JGmTrDL3qKPgb3/zVw0vvujP+mvXhvPOg0svhT59oGXLilcmQ8XuehIRQHc9STolO9DHNGwIF1/sk0OvXtCkScnxFb09VUQqheooJDXO+TtzNm/2ry1bSr4nGlanTsn772MaNoRJk/y98Lm5ydc5enTiMvqq/FepiFSIEsWBYvduX1mb6J76hQv92Xsq97/n5vqrgsaN/Xv79rB0acl569Xzd+z07l368mJFRCo6Eqm2lCiqi1274P33YfXqxMlgw4b952nY0N8yuX59yfqAunXhxhv9v0NjCSGWHA46aP/lVLSOYNAgJQaRakx1FNnu66/92fuf/uT/aRtzyCHJ76cP31evOgIRQXUUB6bly+EPf4Bx43z5/oUX+n8Sn3iiv5uoQYPUllPRlkNFpMZTosgmzvk/kT34oL/ltE4dX2QzahR07Fi+ZR51VPLbW0VEUqDnUWSDwkLfxMUpp8DZZ8Pbb/s6gVWr4IknYPHi8j9PIRvasheRak1XFJm0datvAvrhh31RULt2vnjpuuv2HdzjWw6NPTgHUqsg1l1HIlJBqszOhM8/98nh0Udh2zZ/FfHTn8Ill+zfzpAqo0WkEqgyu7qYO9fXP0yZ4vuvvBJ+8hP/TIFkVBktIhmmRFEVnPMtlj7wgL9lddQouOUW31x1aVQZLSIZpsrsdCsqgh/9yCeJ4cP9H+buvz+1JAGqjBaRjFOiSKe9e/0/oMeMgVtv9RXVBx9ctmUMGuQf+9mmjW9xtU2bsj1vWUSkglT0lC6FhTB0qH+g/F13wX33lf/pY2oCQ0QySIkiHfbsgcGD4bnn4Je/9IlCRKSaSmvRk5n1NLNPzGy5md2eYHwbM5tpZovN7E0za5XOeKrErl3+MZ/PPefrJZQkRKSaS1uiMLMcYAxwMXAiMNDMToyb7AFgvHPuJOA+4DfpiqdK7Njhn4P84ou+Eb+f/jTTEYmIVFg6ryi6A8udc58553YDk4C+cdOcCMwKumcnGF99fPutb7b71Vd9ZfNNN2U6IhGRSpHORNESWB3qXxMMC1sEXBZ09wMamVmz+AWZ2Q1mNs/M5m3cuDEtwVbItm3+caCzZ/vWXocNy3REIiKVJtO3x94KnGNm/wHOAdYC+z2GzTk31jnXzTnXrUWLFlUdY7TNm30T4HPmwLPPwrXXZjoiEZFKlc67ntYC4X+VtQqGFXPOfUFwRWFmDYHLnXOb0xhT5dq0ySeJDz/0zXL065fpiEREKl06ryjmAu3M7GgzqwsMAKaFJzCz5mYWi+EXwBNpjKdyffklnHceLFkCL7ygJCEiB6y0JQrnXCFwM/Aa8DHwnHNuiZndZ2Z9gsl6AJ+Y2X+Bw4Dq0S7FF19Ajx7w6afwz39Cr17R00+YUP7nSYiIZJiaGS+r1av9lcT69fDyy76J8Cjxz5MA31aTmuEQkSpUkWbGM12ZXb2sXOkTw5dfwuuvl54kwD8wKJwkwPffeWd6YhQRqWRqwiNV+fk+MXz7LcycGf0MiTA9T0JEqjldUaTq17/2dznNnp16koDkz43Q8yREpJpQokhFQQFMnuzbcMrLK9u8ep6EiFRzShSpmDoVtm6F668v+7x6noSIVHO66ykVF1wAn30Gy5f7W1xFRKoZ3fWUTqtWwaxZcN11ShIiUiPpyFea8ePBOZ8oRERqICWKKEVFvjXY887z/6gWEamBlCiivPOOr5soTyW2iMgBQokiyrhx0KgRXHZZqZOKiByolCiS2b7dNx1+1VX7/w9CRKQGUaJIZsoU31yHip1EpIZTokjmySfhuOPgtNMyHYmISEYpUSSyfLmvyB4yxP+bWkSkBlOiSOSpp/yf6/T8axERJYr97N3rE8WFF0LLlpmORkQk45Qo4s2e7Z9iN2RIpiMREckKShTxnnwSmjSBvn0zHYmISFZQogjbvBn+8Q+4+mrIzc10NCIiWUGJImzyZNi5U8VOIiIhShRh48ZBhw5le9SpiMgBToki5uOP4f33/T+x9d8JEZFiShQx48ZBTg4MHpzpSEREsooSBUBhITz9NPTqBYcdluloRESyihIFwOuvw7p1agBQRCQBJQrw/51o3hx69048fsIE/4S7WrX8+4QJVRmdiEhG1c50ABm3aRNMmwYjRkDduvuPnzABbrgBCgp8/6pVvh9g0KCqi1NEJEN0RTFxIuzenbzY6c479yWJmIICP1xEpAZQonjySejcGfLyEo///POyDRcROcDU7ESxeDEsWBBdiX3UUWUbLiJygKnZiWLcOKhTBwYOTD7N6NH7PzO7fn0/XESkBqi5iWLPHnjmGejTx9/xlMygQTB2LLRp4/+x3aaN71dFtojUEDX3rqeXX4aNG1P778SgQUoMIlJj1dwrinHj4PDD4aKLMh2JiEhWq5mJ4ssv/RXFNddA7Zp7USUikoqamSieeca376QmO0RESlXzEoVz/r8Tp5wCJ5yQ6WhERLJezUsUCxbARx/pKXYiIilKa6Iws55m9omZLTez2xOMP8rMZpvZf8xssZn1Smc8gL+ayM2FAQPSvioRkQNB2hKFmeUAY4CLgROBgWZ2YtxkdwHPOec6AwOAP6crHsA/D/vZZ6FfP2jSJK2rEhE5UKTziqI7sNw595lzbjcwCegbN40DDg66GwNfpDEeeOkl+OYbFTuJiJRBOhNFS2B1qH9NMCzsXmCwma0BpgM/SrQgM7vBzOaZ2byNGzeWP6Inn4RWreD888u/DBGRGqbURGFm3zezdCWUgcA451wroBfwdKJ1OefGOue6Oee6tWjRonxrWrsWXnsNrrvOPxtbRERSkkoCuAr41Mx+b2bHl2HZa4HWof5WwbCwHwDPATjn3gNygYiGlyrg6aehqMgnChERSVmpicI5NxjoDKwAxpnZe0FRUKNSZp0LtDOzo82sLr6yelrcNJ8D5wOY2Qn4RFGBsqUIAwfCo49Cu3ZpWbyIyIEqpSIl59xW4O/4CukjgH7AAjNLWKcQzFMI3Ay8BnyMv7tpiZndZ2Z9gsl+Cgwzs0XARGCIc86V+9NEadMGfvjDtCxaRORAVmpDR8FB/XrgWGA80N0596WZ1QeWAn9MNq9zbjq+kjo87O5Q91LgjPKFLiIiVSGVFvEuB/7gnHs7PNA5V2BmP0hPWCIiki1SSRT3AutiPWZWDzjMOZfvnJuZrsBERCQ7pFJHMQUoCvXvDYaJiEgNkEqiqB38sxqAoLtu+kISEZFskkqi2Bi6Swkz6wt8lb6QREQkm6RSRzEcmGBmfwIM3yzHtWmNSkREskapicI5twI41cwaBv3b0x6ViIhkjZQeGG1mvYEOQK6ZAeCcuy+NcYmISJZIpVHAv+Lbe/oRvuipP9AmzXGJiEiWSKUy+3Tn3LXAN865/wVOA45Lb1giIpItUkkUO4P3AjM7EtiDb+9JRERqgFTqKF4ysybA/cAC/FPpHk1rVCIikjUiE0XwEKGZzrnNwPNm9k8g1zm3pUqiExGRjIssenLOFQFjQv27lCRERGqWVOooZprZ5Ra7L1ZERGqUVBLFjfhGAHeZ2VYz22ZmW9Mcl4iIZIlU/pld2iNPRUTkAJbKE+7OTjQ8/kFGIiJyYErl9tifhbpzge7AfOC8tEQkIiJZJZWip++H+82sNfBQ2iISEZGskkpldrw1wAmVHYiIiGSnVOoo/oj/Nzb4xNIJ/w9tERGpAVKpo5gX6i4EJjrn3k1TPCIikmVSSRR/B3Y65/YCmFmOmdV3zhWkNzQREckGKf0zG6gX6q8HzEhPOCIikm1SSRS54cefBt310xeSiIhkk1QSxbdm1iXWY2ZdgR3pC0lERLJJKnUUI4EpZvYF/lGoh+MfjSoiIjVAKn+4m2tmxwPtg0GfOOf2pDcsERHJFqUWPZnZTUAD59xHzrmPgIZm9v/SH5qIiGSDVOoohgVPuAPAOfcNMCx9IYmISDZJJVHkhB9aZGY5QN30hSQiItkklcrsV4HJZva3oP9G4JX0hSQiItkklUTxc+AGYHjQvxh/55OIiNQApRY9OeeKgH8D+fhnUZwHfJzesEREJFskvaIws+OAgcHrK2AygHPu3KoJTUREskFU0dMy4B3gEufccgAzG1UlUYmISNaIKnq6DFgHzDazR83sfPw/s0VEpAZJmiiccy845wYAxwOz8U15HGpmfzGzC6sqQBERyaxUKrO/dc49Gzw7uxXwH/ydUCIiUgOU6ZnZzrlvnHNjnXPnpzK9mfU0s0/MbLmZ3Z5g/B/MbGHw+q+ZbU60HBERyZxU/kdRLsE/uMcA3wPWAHPNbJpzbmlsGufcqND0PwI6pyseEREpnzJdUZRRd2C5c+4z59xuYBLQN2L6gcDENMYjIiLlkM5E0RJYHepfEwzbj5m1AY4GZiUZf4OZzTOzeRs3bqz0QEVEJLl0JoqyGAD83Tm3N9HIoF6km3OuW4sWLao4NBGRmi2diWIt0DrU3yoYlsgAVOwkIpKV0pko5gLtzOxoM6uLTwbT4icKnp53CPBeGmMREZFySluicM4VAjcDr+EbEXzOObfEzO4zsz6hSQcAk5xzLl2xiIhI+aXt9lgA59x0YHrcsLvj+u9NZwwiIlIx2VKZLSIiWUqJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRamc6ABEpnz179rBmzRp27tyZ6VAki+Tm5tKqVSvq1KlTactUohCpptasWUOjRo1o27YtZpbpcCQLOOfYtGkTa9as4eijj6605aa16MnMeprZJ2a23MxuTzLNlWa21MyWmNmz6YxH5ECyc+dOmjVrpiQhxcyMZs2aVfpVZtquKMwsBxgDfA9YA8w1s2nOuaWhadoBvwDOcM59Y2aHpisekQORkoTES8c+kc4riu7AcufcZ8653cAkoG/cNMOAMc65bwCcc1+mMR4RESmHdCaKlsDqUP+aYFjYccBxZvaumb1vZj0TLcjMbjCzeWY2b+PGjWkKV+QAN2ECtG0LtWr59wkTKrS4TZs20alTJzp16sThhx9Oy5Yti/t3794dOe+8efO45ZZbSl3H6aefXqEY440cOZKWLVtSVFRUqcs90GW6Mrs20A7oAbQC3jazjs65zeGJnHNjgbEA3bp1c1UdpEi1N2EC3HADFBT4/lWrfD/AoHBa+YEAABGUSURBVEHlWmSzZs1YuHAhAPfeey8NGzbk1ltvLR5fWFhI7dqJDzHdunWjW7dupa5jzpw55YotkaKiIqZOnUrr1q156623OPfccytt2WFRn7u6SucVxVqgdai/VTAsbA0wzTm3xzm3EvgvPnGISGW68859SSKmoMAPr0RDhgxh+PDhnHLKKdx222188MEHnHbaaXTu3JnTTz+dTz75BIA333yTSy65BPBJZujQofTo0YNjjjmGRx55pHh5DRs2LJ6+R48eXHHFFRx//PEMGjQI5/w54/Tp0zn++OPp2rUrt9xyS/Fy47355pt06NCBESNGMHHixOLhGzZsoF+/fuTl5ZGXl1ecnMaPH89JJ51EXl4e11xzTfHn+/vf/54wvrPOOos+ffpw4oknAnDppZfStWtXOnTowNixY4vnefXVV+nSpQt5eXmcf/75FBUV0a5dO2KlJUVFRRx77LFkU+lJOtPeXKCdmR2NTxADgKvjpnkBGAg8aWbN8UVRn6UxJpGa6fPPyza8AtasWcOcOXPIyclh69atvPPOO9SuXZsZM2Zwxx138Pzzz+83z7Jly5g9ezbbtm2jffv2jBgxYr//AfznP/9hyZIlHHnkkZxxxhm8++67dOvWjRtvvJG3336bo48+moEDByaNa+LEiQwcOJC+fftyxx13sGfPHurUqcMtt9zCOeecw9SpU9m7dy/bt29nyZIl/OpXv2LOnDk0b96cr7/+utTPvWDBAj766KPi21KfeOIJmjZtyo4dOzj55JO5/PLLKSoqYtiwYcXxfv3119SqVYvBgwczYcIERo4cyYwZM8jLy6NFixZl3PLpk7YrCudcIXAz8BrwMfCcc26Jmd1nZn2CyV4DNpnZUmA28DPn3KZ0xSRSYx11VNmGV0D//v3JyckBYMuWLfTv35/vfve7jBo1iiVLliScp3fv3hx00EE0b96cQw89lA0bNuw3Tffu3WnVqhW1atWiU6dO5Ofns2zZMo455pjig3OyRLF7926mT5/OpZdeysEHH8wpp5zCa6+9BsCsWbMYMWIEADk5OTRu3JhZs2bRv39/mjdvDkDTpk1L/dzdu3cv8d+FRx55hLy8PE499VRWr17Np59+yvvvv8/ZZ59dPF1suUOHDmX8+PGATzDXX399qeurSmktSHPOTQemxw27O9TtgJ8ELxFJl9GjS9ZRANSv74dXsgYNGhR3/8///A/nnnsuU6dOJT8/nx49eiSc56CDDiruzsnJobCwsFzTJPPaa6+xefNmOnbsCEBBQQH16tVLWkyVTO3atYsrwouKikpU2oc/95tvvsmMGTN47733qF+/Pj169Ij8b0Pr1q057LDDmDVrFh988AETKnijQWVTW08iNcGgQTB2LLRpA2b+fezYcldkp2rLli20bOlvdhw3blylL799+/Z89tln5OfnAzB58uSE002cOJHHHnuM/Px88vPzWblyJW+88QYFBQWcf/75/OUvfwFg7969bNmyhfPOO48pU6awaZMv4IgVPbVt25b58+cDMG3aNPbs2ZNwfVu2bOGQQw6hfv36LFu2jPfffx+AU089lbfffpuVK1eWWC7AD3/4QwYPHlziiixbKFGI1BSDBkF+PhQV+fc0JwmA2267jV/84hd07ty5TFcAqapXrx5//vOf6dmzJ127dqVRo0Y0bty4xDQFBQW8+uqr9O7du3hYgwYNOPPMM3nppZd4+OGHmT17Nh07dqRr164sXbqUDh06cOedd3LOOeeQl5fHT37iCz2GDRvGW2+9RV5eHu+9916Jq4iwnj17UlhYyAknnMDtt9/OqaeeCkCLFi0YO3Ysl112GXl5eVx11VXF8/Tp04ft27dnXbETgMXuHKguunXr5ubNm5fpMEQy7uOPP+aEE07IdBgZt337dho2bIhzjptuuol27doxatSoTIdVZvPmzWPUqFG88847FV5Won3DzOY750q/JzkBXVGISLX26KOP0qlTJzp06MCWLVu48cYbMx1Smf32t7/l8ssv5ze/+U2mQ0lIVxQi1ZSuKCQZXVGIiEiVUqIQEZFIShQiIhJJiUJERCIpUYhIuZx77rnFzWDEPPTQQ8XNYSTSo0cPYjej9OrVi82bN+83zb333ssDDzwQue4XXniBpUuLn4HG3XffzYwZM8oSfiQ1R16SEoWIlMvAgQOZNGlSiWGTJk2KbJgvbPr06TRp0qRc645PFPfddx8XXHBBuZYVL7458nRJxx8Q00WJQuRAMHIk9OhRua+RIyNXecUVV/Dyyy8Xt3eUn5/PF198wVlnncWIESPo1q0bHTp04J577kk4f9u2bfnqq68AGD16NMcddxxnnnlmcVPk4P8jcfLJJ5OXl8fll19OQUEBc+bMYdq0afzsZz+jU6dOrFixokTz3zNnzqRz58507NiRoUOHsmvXruL13XPPPXTp0oWOHTuybNmyhHGpOfL9KVGISLk0bdqU7t2788orrwD+auLKK6/EzBg9ejTz5s1j8eLFvPXWWyxevDjpcubPn8+kSZNYuHAh06dPZ+7cucXjLrvsMubOncuiRYs44YQTePzxxzn99NPp06cP999/PwsXLuQ73/lO8fQ7d+5kyJAhTJ48mQ8//JDCwsLidpwAmjdvzoIFCxgxYkTS4q1Yc+T9+vXj5ZdfLm7PKdYc+aJFi1iwYAEdOnQobo581qxZLFq0iIcffrjU7bZgwQIefvhh/vvf/wK+tdj58+czb948HnnkETZt2sTGjRsZNmwYzz//PIsWLWLKlCklmiMHqrQ58gPrMUwiNdVDD2VktbHip759+zJp0iQef/xxAJ577jnGjh1LYWEh69atY+nSpZx00kkJl/HOO+/Qr18/6tevD/g2j2I++ugj7rrrLjZv3sz27du56KKLIuP55JNPOProoznuuOMAuO666xgzZgwjg6ujyy67DICuXbvyj3/8Y7/5Y82RP/jggzRq1Ki4OfJLLrmEWbNmFTcFHmuOfPz48ZXSHPnUqVMBipsj37hxY9LmyPv27cvIkSOrtDnymnFFUcnPChYRr2/fvsycOZMFCxZQUFBA165dWblyJQ888AAzZ85k8eLF9O7dO7KJ7ShDhgzhT3/6Ex9++CH33HNPuZcTE2uqPFkz5eHmyNu2bcu//vWvEsVPqSpPc+SLFi2ic+fOZWqO/OKLLy5zbOVx4CeK2LOCV60C5/Y9K1jJQqTCGjZsyLnnnsvQoUOLK7G3bt1KgwYNaNy4MRs2bCgumkrm7LPP5oUXXmDHjh1s27aNl156qXjctm3bOOKII9izZ0+JZzQ0atSIbdu27bes9u3bk5+fz/LlywF4+umnOeecc1L+PGqOPLEDP1FU0bOCRWqqgQMHsmjRouJEkZeXR+fOnTn++OO5+uqrOeOMMyLn79KlC1dddRV5eXlcfPHFnHzyycXjfvnLX3LKKadwxhlncPzxxxcPHzBgAPfffz+dO3dmxYoVxcNzc3N58skn6d+/Px07dqRWrVoMHz48pc+h5siTO/AbBaxVy19JxDPz7fKLVFNqFLBmSqU5cjUKWFZV+KxgEZF0ylRz5Ad+ohg92j8bOCxNzwoWEUmn22+/nVWrVnHmmWdW6XoP/ESRoWcFi1SF6lZ0LOmXjn2iZvyPYtAgJQY54OTm5rJp0yaaNWuGmWU6HMkCzjk2bdpEbm5upS63ZiQKkQNQq1atWLNmTZU04SDVR25uLq1atarUZSpRiFRTderUKfEPX5F0OfDrKEREpEKUKEREJJIShYiIRKp2/8w2s43AqkzHkURz4KtMBxFB8VVMtscH2R+j4quYisTXxjlXrjbJq12iyGZmNq+8f5GvCoqvYrI9Psj+GBVfxWQqPhU9iYhIJCUKERGJpERRucaWPklGKb6Kyfb4IPtjVHwVk5H4VEchIiKRdEUhIiKRlChERCSSEkUZmVlrM5ttZkvNbImZ/TjBND3MbIuZLQxed1dxjPlm9mGw7v0eB2jeI2a23MwWm1mXKoytfWi7LDSzrWY2Mm6aKt9+ZvaEmX1pZh+FhjU1szfM7NPg/ZAk814XTPOpmV1XRbHdb2bLgu9vqpk1STJv5L6Q5hjvNbO1oe+xV5J5e5rZJ8H+eHsVxjc5FFu+mS1MMm9at2GyY0q27H+Ab5ZWr9RfwBFAl6C7EfBf4MS4aXoA/8xgjPlA84jxvYBXAANOBf6doThzgPX4PwJldPsBZwNdgI9Cw34P3B503w78LsF8TYHPgvdDgu5DqiC2C4HaQffvEsWWyr6Q5hjvBW5NYR9YARwD1AUWxf+e0hVf3Pj/A+7OxDZMdkzJlv3POacrirJyzq1zzi0IurcBHwMtMxtVmfUFxjvvfaCJmR2RgTjOB1Y45zL+T3vn3NvA13GD+wJPBd1PAZcmmPUi4A3n3NfOuW+AN4Ce6Y7NOfe6c64w6H0fqNx2pcsoyfZLRXdguXPuM+fcbmASfrtXqqj4zD/M40pgYmWvNxURx5Ss2P9ARU8VYmZtgc7AvxOMPs3MFpnZK2bWoUoDAwe8bmbzzeyGBONbAqtD/WvITLIbQPIfZya3X8xhzrl1Qfd64LAE02TDthyKv0JMpLR9Id1uDorHnkhSdJIN2+8sYINz7tMk46tsG8YdU7Jm/1OiKCczawg8D4x0zm2NG70AX5ySB/wReKGKwzvTOdcFuBi4yczOruL1l8rM6gJ9gCkJRmd6++3H+ev8rLuX3MzuBAqBCUkmyeS+8BfgO0AnYB2+eCcbDST6aqJKtmHUMSXT+58SRTmYWR38FzrBOfeP+PHOua3Oue1B93Sgjpk1r6r4nHNrg/cvgan4y/uwtUDrUH+rYFhVuhhY4JzbED8i09svZEOsSC54/zLBNBnblmY2BLgEGBQcSPaTwr6QNs65Dc65vc65IuDRJOvO6L5oZrWBy4DJyaapim2Y5JiSNfufEkUZBeWZjwMfO+ceTDLN4cF0mFl3/HbeVEXxNTCzRrFufKXnR3GTTQOuDe5+OhXYErrErSpJz+Iyuf3iTANid5FcB7yYYJrXgAvN7JCgaOXCYFhamVlP4Dagj3OuIMk0qewL6YwxXO/VL8m65wLtzOzo4CpzAH67V5ULgGXOuTWJRlbFNow4pmTP/peumvwD9QWcib8EXAwsDF69gOHA8GCam4El+Ds43gdOr8L4jgnWuyiI4c5geDg+A8bg7zb5EOhWxduwAf7A3zg0LKPbD5+01gF78OW8PwCaATOBT4EZQNNg2m7AY6F5hwLLg9f1VRTbcnzZdGwf/Gsw7ZHA9Kh9oQq339PB/rUYf9A7Ij7GoL8X/k6fFemKMVF8wfBxsf0uNG2VbsOIY0pW7H/OOTXhISIi0VT0JCIikZQoREQkkhKFiIhEUqIQEZFIShQiIhJJiUIkYGZ7rWTLtpXWkqmZtQ23XCpSndTOdAAiWWSHc65TpoMQyTa6ohApRfA8gt8HzyT4wMyODYa3NbNZQaN3M83sqGD4YeafEbEoeJ0eLCrHzB4NnjnwupnVC6a/JXgWwWIzm5ShjymSlBKFyD714oqergqN2+Kc6wj8CXgoGPZH4Cnn3En4RvkeCYY/ArzlfKOGXfD/6AVoB4xxznUANgOXB8NvBzoHyxmerg8nUl76Z7ZIwMy2O+caJhieD5znnPssaLxtvXOumZl9hW+WYk8wfJ1zrrmZbQRaOed2hZbRFv/cgHZB/8+BOs65X5nZq8B2fCu5L7igQUSRbKErCpHUuCTdZbEr1L2XfXWEvfFtb3UB5gYtmopkDSUKkdRcFXp/L+ieg2/tFGAQ8E7QPRMYAWBmOWbWONlCzawW0No5Nxv4OdAY2O+qRiSTdOYisk89M1sY6n/VORe7RfYQM1uMvyoYGAz7EfCkmf0M2AhcHwz/MTDWzH6Av3IYgW+5NJEc4JkgmRjwiHNuc6V9IpFKoDoKkVIEdRTdnHNfZToWkUxQ0ZOIiETSFYWIiETSFYWIiERSohARkUhKFCIiEkmJQkREIilRiIhIpP8Prxg/x+2YXlMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnbwRktGU7mG",
        "outputId": "4899379c-32cf-4584-cc66-44d970b190c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "model_df = pd.DataFrame(model_history.history)\n",
        "model_df"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.858282</td>\n",
              "      <td>0.552243</td>\n",
              "      <td>0.742629</td>\n",
              "      <td>0.795516</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.616927</td>\n",
              "      <td>0.827422</td>\n",
              "      <td>0.402989</td>\n",
              "      <td>0.883442</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.387309</td>\n",
              "      <td>0.885696</td>\n",
              "      <td>0.294447</td>\n",
              "      <td>0.915637</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.271936</td>\n",
              "      <td>0.918201</td>\n",
              "      <td>0.233475</td>\n",
              "      <td>0.930512</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.233711</td>\n",
              "      <td>0.930173</td>\n",
              "      <td>0.221141</td>\n",
              "      <td>0.934143</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.195550</td>\n",
              "      <td>0.940618</td>\n",
              "      <td>0.210276</td>\n",
              "      <td>0.936169</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.184719</td>\n",
              "      <td>0.942205</td>\n",
              "      <td>0.184310</td>\n",
              "      <td>0.946575</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.165081</td>\n",
              "      <td>0.948729</td>\n",
              "      <td>0.175929</td>\n",
              "      <td>0.947413</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.148249</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.172237</td>\n",
              "      <td>0.947343</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.138716</td>\n",
              "      <td>0.954536</td>\n",
              "      <td>0.170350</td>\n",
              "      <td>0.947901</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.152211</td>\n",
              "      <td>0.950884</td>\n",
              "      <td>0.173991</td>\n",
              "      <td>0.949438</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.134475</td>\n",
              "      <td>0.956003</td>\n",
              "      <td>0.179548</td>\n",
              "      <td>0.948041</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.119296</td>\n",
              "      <td>0.959205</td>\n",
              "      <td>0.159925</td>\n",
              "      <td>0.951673</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.113216</td>\n",
              "      <td>0.962048</td>\n",
              "      <td>0.162219</td>\n",
              "      <td>0.950695</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.112733</td>\n",
              "      <td>0.960312</td>\n",
              "      <td>0.162581</td>\n",
              "      <td>0.951463</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.111416</td>\n",
              "      <td>0.961270</td>\n",
              "      <td>0.161759</td>\n",
              "      <td>0.951114</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.109696</td>\n",
              "      <td>0.961121</td>\n",
              "      <td>0.162023</td>\n",
              "      <td>0.951184</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.109024</td>\n",
              "      <td>0.961390</td>\n",
              "      <td>0.162195</td>\n",
              "      <td>0.951812</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.108305</td>\n",
              "      <td>0.961510</td>\n",
              "      <td>0.161448</td>\n",
              "      <td>0.951603</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.108488</td>\n",
              "      <td>0.962198</td>\n",
              "      <td>0.162092</td>\n",
              "      <td>0.951742</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy      lr\n",
              "0   1.858282  0.552243  0.742629      0.795516  0.0010\n",
              "1   0.616927  0.827422  0.402989      0.883442  0.0010\n",
              "2   0.387309  0.885696  0.294447      0.915637  0.0010\n",
              "3   0.271936  0.918201  0.233475      0.930512  0.0010\n",
              "4   0.233711  0.930173  0.221141      0.934143  0.0010\n",
              "5   0.195550  0.940618  0.210276      0.936169  0.0010\n",
              "6   0.184719  0.942205  0.184310      0.946575  0.0010\n",
              "7   0.165081  0.948729  0.175929      0.947413  0.0010\n",
              "8   0.148249  0.951872  0.172237      0.947343  0.0010\n",
              "9   0.138716  0.954536  0.170350      0.947901  0.0010\n",
              "10  0.152211  0.950884  0.173991      0.949438  0.0010\n",
              "11  0.134475  0.956003  0.179548      0.948041  0.0010\n",
              "12  0.119296  0.959205  0.159925      0.951673  0.0002\n",
              "13  0.113216  0.962048  0.162219      0.950695  0.0002\n",
              "14  0.112733  0.960312  0.162581      0.951463  0.0002\n",
              "15  0.111416  0.961270  0.161759      0.951114  0.0001\n",
              "16  0.109696  0.961121  0.162023      0.951184  0.0001\n",
              "17  0.109024  0.961390  0.162195      0.951812  0.0001\n",
              "18  0.108305  0.961510  0.161448      0.951603  0.0001\n",
              "19  0.108488  0.962198  0.162092      0.951742  0.0001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPG-tPh9GaMB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}